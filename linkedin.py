# -*- coding: utf-8 -*-
"""Copy of Session_2_Build_LinkedIn_Post_Generator_App

Automatically generated by Colab.

Original file is located at


# LinkedIn Post Generator App

Here we will build an AI Application using Gemini, LangChain and Streamlit with the following features:

- Custom Landing Page
- LinkedIn Post Generation
- Streamlit features

## Install App and LLM dependencies
"""

# !pip install langchain==0.1.12 -q
# !pip install langchain-google-genai==0.0.7 -q
# !pip install langchain-community==0.0.29 -q
# !pip install streamlit==1.32.2 -q
# !pip install pyngrok==7.1.5 -q
# !pip install google-generativeai>=0.3.2 -q

import streamlit as st
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate

# Function to store API key
def setup_api_key(key: str):
    os.environ["GOOGLE_API_KEY"] = key
    st.session_state.api_key_set = True

# Initialize session state variable
if "api_key_set" not in st.session_state:
    st.session_state.api_key_set = False

# App title
st.title("LinkedIn Post Generator")

# API Key input
api_key = st.text_input("Enter Gemini API Key:", type="password")

if api_key:
    if st.button("Set API Key"):
        setup_api_key(api_key)
        st.success("API Key set successfully!")

st.divider()

# Only allow post generation after key is set
if st.session_state.api_key_set:
    # Define system prompt
    system_prompt = """You are a professional LinkedIn post generator.
    Your task is to create engaging, professional posts for LinkedIn based on the topic provided by the user.

    Follow these guidelines:
    - Keep posts between 150-300 words
    - Include relevant hashtags (3-5)
    - Maintain a professional but conversational tone
    - Focus on providing value to the reader
    - Structure posts with short paragraphs for readability
    - Avoid clickbait and exaggerated claims

    The user will provide a topic or idea for the post."""

    try:
        # Initialize Gemini model
        gemini = ChatGoogleGenerativeAI(
            model='gemini-2.0-flash-thinking-exp-01-21',
            temperature=0.7,
            convert_system_message_to_human=True
        )

        # Prompt template
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{user_input}")
        ])

        # App instructions
        st.markdown("### Generate professional LinkedIn posts with AI")
        st.markdown("Enter a topic or idea to get a LinkedIn post tailored to your needs.")

        # User input field
        user_input = st.text_area(
            "What would you like to post about?",
            placeholder="Example: Sharing my thoughts on the future of AI in healthcare",
            height=100
        )

        # Generate button
        if st.button("Generate Post"):
            if user_input:
                with st.spinner("Creating your LinkedIn post..."):
                    messages = prompt_template.format_messages(user_input=user_input)
                    response = gemini.invoke(messages)

                    # Display result
                    st.markdown("### Your LinkedIn Post:")
                    st.markdown(response.content)
                    st.markdown("---")
                    st.markdown("Copy this post to your clipboard and share it on LinkedIn!")
            else:
                st.error("Please enter a topic for your LinkedIn post.")
    except Exception as e:
        st.error(f"Error initializing Gemini model: {str(e)}")
else:
    st.info("Please enter and set your Gemini API key to begin.")


